import cv2
import numpy as np
from time import time
import os
import database



import logging
log = logging.getLogger(__name__)


from sys import argv

import base64
from PIL import Image
from io import BytesIO

class EyeGaze:
    
    def decode_image(self, image_string) :
	imgdata = base64.b64decode(image_string[22:])
	frame = Image.open(BytesIO(imgdata))
	frame = np.array(frame)
	return frame


    def get_path(self, path, course_name, block_id, student_name):
        
	directory = path + "/" + course_name + "/" + block_id + "/" + student_name
        return directory + "/"

    def decode_json(self, path, course_name, block_id, student_name) :
	with open(self.get_path(path, course_name, block_id, student_name) + 'json_data.txt', 'r') as json_file:
               image_string = json_file.read().replace('\n', '')
	return image_string


    def detect(self, path, student_name, course_name, block_id):
	image_string = self.decode_json(path, course_name, block_id, student_name)
	frame = self.decode_image(image_string)
	log.info("Line 2")
        # Load the Haar-Cascade and
        # retrieve Cascade to detect eyes from the same
        eye_cascade_path = "/edx/app/edxapp/venvs/proctor/lib/python2.7/site-packages/suspicious_images/haarcascade_eye.xml"
        eye_cascade = cv2.CascadeClassifier(eye_cascade_path)

        # A boolean variable which stores if the person was cheating in the frame
        cheat_bool = 0

        # reduce the noise in image by blurring and the blurred image to
        # original image so as to subtract local mean color image.
        blurred = cv2.GaussianBlur(frame, (21, 21), 0)
        weight_frame = cv2.addWeighted(frame, 1.75, blurred, -0.5, 0)

        # Equalise histogram to improve the contrast (Removing glare)
        # - Need to convert it to YUV image
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV)
        yuv[:, :, 0] = cv2.equalizeHist(yuv[:, :, 0])
        # reconvert the image to grayscale to be feeded to Clahe
        bgr_frame = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR)
        gray = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2GRAY)

        # again apply Contrast Limited Adaptive Histogram Equalisation
        # can only work on grayscale images
        clahe = cv2.createCLAHE(clipLimit=40.0, tileGridSize=(8, 8))
        gray = clahe.apply(gray)

        # load the haar-cascade to get the region of interest - eye_region
        eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=3)

        # How many times to load the haar-cascade to increase effectiveness
        sample_tries = 2
        while sample_tries:
            for (x, y, width, height) in eyes:
                cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)
                break

            sample_tries -= 1

            # if already eyes are recongnized - break out of loop
            if len(eyes):
                break
        # If no eye_region is found, that would mean that either the person's face is not
        # straightly oriented in front of webcam or he is cheating - In any case mark as suspicious
        if len(eyes) == 0:
            cheat_bool = 1

        else:
            # crop the right portion of the eyes to enable accurate detection of pupil,
            # blur that region again to reduce noise.
            gray_cropped_right = gray[eyes[0][1]: eyes[0][1] + eyes[0][3],
                                      eyes[0][0] + eyes[0][2] / 2: eyes[0][0] + eyes[0][2]]
            cv2.GaussianBlur(gray_cropped_right, (3, 3), 16)

            # use HoughCircles method to detect the circular shape in right part of eye (cropped earlier)
            circles_right = cv2.HoughCircles(gray_cropped_right, cv2.cv.CV_HOUGH_GRADIENT,
                                             dp=5, minDist=60, param1=30, param2=10, minRadius=5, maxRadius=20)
            try:
                # find the pupil-positions corresponding to the circle region
                pupil_position = np.uint16(np.around(circles_right))

                # form a small circle around the pupil-position
                for (a, b, radius) in pupil_position[0]:
                    cv2.circle(frame, (a + x + width / 2, b + y), 2, (255, 0, 0), 2)

            except:
                pass
        # If the user is found to be cheating, the corresponding images can be saved in the directory
        if cheat_bool == 1:
            # TODO Increament this variable in database using some course_name/student_name
            	student_id = database.get_id(student_name)
		database.update_table(student_id, course_name, "img_count", 1)

        	path_img = self.get_path(path, course_name, block_id, student_name) + "/susp_img"

		if not os.path.exists(path_img):
            		os.makedirs(path_img)

		path_img += "/"

 		cv2.imwrite(path_img + str(len(os.listdir(path_img))) + ".jpg", frame)

if __name__ == "__main__":
        gaze = EyeGaze()
	#sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4], sys.argv[5]
	#with open('/edx/app/edxapp/venvs/edxapp/lib/python2.7/site-packages/eproctoring_xblock/json_data', 'r') as json_file:
    	#	image_string = json_file.read().replace('\n', '')
        #gaze.detect("/edx/app/edxapp/venvs/proctor/lib/python2.7/site-packages/", "prnv", "OS", "Block", image_string)
	log.info(argv[1])
	log.info(argv[2])
	gaze.detect(argv[1], argv[2], argv[3], argv[4])
